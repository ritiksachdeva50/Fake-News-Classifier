{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake News Classifier Using Bidirectional LSTM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>author</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n      <td>Darrell Lucus</td>\n      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n      <td>Daniel J. Flynn</td>\n      <td>Ever get the feeling your life circles the rou...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Why the Truth Might Get You Fired</td>\n      <td>Consortiumnews.com</td>\n      <td>Why the Truth Might Get You Fired October 29, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n      <td>Jessica Purkiss</td>\n      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Iranian woman jailed for fictional unpublished...</td>\n      <td>Howard Portnoy</td>\n      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Drop Nan Values\n",
    "df=df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Independent Features\n",
    "\n",
    "X=df.drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the Dependent features\n",
    "y=df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    10361\n",
       "1     7924\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vocabulary size\n",
    "voc_size=5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onehot Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Smarak\n[nltk_data]     Pradhan\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dataset Preprocessing\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "\n",
    "def preprocess(doc):\n",
    "  doc=re.sub(r'\\W', ' ',str(doc))\n",
    "  doc = doc.lower()                 # Converting to lowercase\n",
    "  cleanr = re.compile('<.*?>')\n",
    "  doc = re.sub(cleanr, ' ',str(doc))        #Removing HTML tags\n",
    "  doc = re.sub(r'[?|!|\\'|\"|#]',r'',str(doc))\n",
    "  doc = re.sub(r'[.|,|)|(|\\|/]',r' ',str(doc))\n",
    "  doc=re.sub(r'\\s+', ' ',str(doc),flags=re.I)\n",
    "  doc=re.sub(r'^b\\s+', ' ',str(doc))\n",
    "  doc = re.sub(r'\\[[0-9]*\\]', ' ', doc)\n",
    "  doc = re.sub(r'\\s+', ' ',doc)\n",
    "  # Removing special characters and digits\n",
    "  doc = re.sub('[^a-zA-Z]', ' ', doc )\n",
    "  doc = re.sub(r'\\s+', ' ', doc)\n",
    "  #doc_list = nltk.sent_tokenize(doc)\n",
    "  stopwords = nltk.corpus.stopwords.words('english')\n",
    "  #Lemmatization\n",
    "  tokens=doc.split()\n",
    "  tokens=[lemma.lemmatize(word) for word in tokens]\n",
    "  tokens=[word for word in tokens if word not in stopwords]\n",
    "  \n",
    "  return tokens\n",
    "corpus=[]\n",
    "for i in range(0,len(messages)) :\n",
    "    tokens=preprocess(messages['title'][i])\n",
    "    tokens=' '.join(tokens)\n",
    "    corpus.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_repr=[one_hot(words,voc_size)for words in corpus] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[   0    0    0 ... 1262  265 1737]\n [   0    0    0 ... 3469 4562 2508]\n [   0    0    0 ... 2922 3952 1476]\n ...\n [   0    0    0 ... 2700 2654 2288]\n [   0    0    0 ... 4275 2653 3703]\n [   0    0    0 ... 3854 3760 4557]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=30\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0, 3726, 2073,\n",
       "        874, 4575,  160, 2220, 4580, 1262,  265, 1737])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "embedded_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 30, 40)            200000    \n_________________________________________________________________\nlstm (LSTM)                  (None, 100)               56400     \n_________________________________________________________________\ndense (Dense)                (None, 1)                 101       \n=================================================================\nTotal params: 256,501\nTrainable params: 256,501\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "## Creating model\n",
    "embedding_vector_features=40\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, 30, 150)           750000    \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 200)               200800    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 200)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 201       \n=================================================================\nTotal params: 951,001\nTrainable params: 951,001\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "## Creating model\n",
    "embedding_vector_features=150\n",
    "model1=Sequential()\n",
    "model1.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model1.add(Bidirectional(LSTM(100)))\n",
    "model1.add(Dropout(0.3))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(18285, (18285,))"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "len(embedded_docs),y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_final=np.array(embedded_docs)\n",
    "y_final=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((18285, 30), (18285,))"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "X_final.shape,y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "192/192 [==============================] - 11s 56ms/step - loss: 0.2989 - accuracy: 0.8626 - val_loss: 0.2006 - val_accuracy: 0.9175\n",
      "Epoch 2/10\n",
      "192/192 [==============================] - 10s 50ms/step - loss: 0.1312 - accuracy: 0.9495 - val_loss: 0.2119 - val_accuracy: 0.9130\n",
      "Epoch 3/10\n",
      "192/192 [==============================] - 10s 50ms/step - loss: 0.0845 - accuracy: 0.9696 - val_loss: 0.2421 - val_accuracy: 0.9157\n",
      "Epoch 4/10\n",
      "192/192 [==============================] - 10s 51ms/step - loss: 0.0475 - accuracy: 0.9845 - val_loss: 0.2966 - val_accuracy: 0.9138\n",
      "Epoch 5/10\n",
      "192/192 [==============================] - 10s 50ms/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 0.3083 - val_accuracy: 0.9145\n",
      "Epoch 6/10\n",
      "192/192 [==============================] - 10s 54ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 0.4378 - val_accuracy: 0.9133\n",
      "Epoch 7/10\n",
      "192/192 [==============================] - 11s 58ms/step - loss: 0.0104 - accuracy: 0.9968 - val_loss: 0.4414 - val_accuracy: 0.9147\n",
      "Epoch 8/10\n",
      "192/192 [==============================] - 11s 58ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.4985 - val_accuracy: 0.9082\n",
      "Epoch 9/10\n",
      "192/192 [==============================] - 10s 54ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.5386 - val_accuracy: 0.9082\n",
      "Epoch 10/10\n",
      "192/192 [==============================] - 10s 54ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.5604 - val_accuracy: 0.9039\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e37c0403a0>"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "### Finally Training\n",
    "model1.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metrics And Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From <ipython-input-33-ccbb315231b5>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\nInstructions for updating:\nPlease use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred1=model1.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[3121,  298],\n",
       "       [ 282, 2334]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.903893951946976"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92      3419\n",
      "           1       0.88      0.91      0.89      2616\n",
      "\n",
      "    accuracy                           0.91      6035\n",
      "   macro avg       0.90      0.91      0.91      6035\n",
      "weighted avg       0.91      0.91      0.91      6035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd010588537bc3f81a35ceb684741d6beb7f73e874ad223cf30a51d7cc1aad9f930",
   "display_name": "Python 3.8.3 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}